/var/spool/slurmd/job1126548/slurm_script: line 8: activate: No such file or directory

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 10.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 11.70s/it]
wandb: Tracking run with wandb version 0.14.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 29457
  Num Epochs = 50
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 46050
  Number of trainable parameters = 85244354
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/46050 [00:00<?, ?it/s]  0%|          | 1/46050 [00:24<316:22:51, 24.73s/it]wandb: Waiting for W&B process to finish... (failed 1).
wandb: - 0.000 MB of 0.000 MB uploaded (0.000 MB deduped)wandb: You can sync this run to the cloud by running:
wandb: wandb sync /lustre/gst/xuchunfu/zhangxt/wandb/offline-run-20230508_200157-556e4u9p
wandb: Find logs at: ./wandb/offline-run-20230508_200157-556e4u9p/logs
Traceback (most recent call last):
  File "/lustre/gst/xuchunfu/zhangxt/ft_plm/ft_token.py", line 151, in <module>
    trainer.train()
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/trainer.py", line 1543, in train
    return inner_training_loop(
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/trainer.py", line 1791, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/trainer.py", line 2539, in training_step
    loss = self.compute_loss(model, inputs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/trainer.py", line 2571, in compute_loss
    outputs = model(**inputs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/models/esm/modeling_esm.py", line 1018, in forward
    outputs = self.esm(
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/models/esm/modeling_esm.py", line 923, in forward
    encoder_outputs = self.encoder(
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/models/esm/modeling_esm.py", line 623, in forward
    layer_outputs = layer_module(
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/models/esm/modeling_esm.py", line 508, in forward
    self_attention_outputs = self.attention(
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/models/esm/modeling_esm.py", line 442, in forward
    self_outputs = self.self(
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/lustre/gst/xuchunfu/zhangxt/anaconda3/envs/protein_predict/lib/python3.8/site-packages/transformers/models/esm/modeling_esm.py", line 366, in forward
    attention_scores = attention_scores + attention_mask
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.12 GiB (GPU 0; 39.41 GiB total capacity; 21.43 GiB already allocated; 6.33 GiB free; 31.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
